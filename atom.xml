<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Usemaster</title>
  
  <subtitle>Usemaster小屋</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-03-26T08:35:30.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Wenjun D(Wendy)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EM算法及其推广</title>
    <link href="http://yoursite.com/2019/03/26/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/"/>
    <id>http://yoursite.com/2019/03/26/EM算法及其推广/</id>
    <published>2019-03-26T01:45:00.000Z</published>
    <updated>2019-03-26T08:35:30.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>EM算法是一种迭代算法，它的每次迭代由两步组成：E步，求期望；M步，求极大，所以称为期望极大算法(Expectation Maximization)，简称EM算法。</p><p>在概率模型有时既含有观测变量，又含有隐变量或者潜在变量，如果概率模型的变量都是观测变量，那么给定数据，可以直接使用极大似然估计或者贝叶斯估计模型参数，但是当模型含有隐变量，就不能简单使用上述方法。<strong>EM算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法</strong>。</p><h4 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h4><h5 id="例子：🌰"><a href="#例子：🌰" class="headerlink" title="例子：🌰"></a>例子：🌰</h5><p>（三个硬币模型）假设有3个硬币，ABC，硬币正面出现的概率分别是$w,p,q$，先抛A，根据其结果选择B或者C抛，正面抛B，反面抛C，然后抛选择出的硬币，正面记1，反面记0，独立重复$n$次，只能观测到抛掷硬币的最终结果，问如何估计三硬币正面出现的概率，即三硬币模型参数。</p><p>将观测数据表示为$Y=(Y_1,Y_2,…,Y_n)^T$，未观测数据表示为$Z=(Z_1,Z_2,…,Z_n)^T$，观测数据的似然函数为$$P(Y|\theta)=\sum\limits_{Z}P(Z|\theta)P(Y|Z,\theta)$$<br>即<br>$$P(Y|\theta)=\prod\limits_{j=1}^{n}[wp^{y_j}(1-p)^{1-y_j}+(1-w)q^{y_j}(1-q)^{1-y_j}]$$</p><p>求模型参数$\theta=(w,p,q)$的极大似然估计，即<br>$$\hat{\theta}=arg\max\limits_{\theta}logP(Y|\theta)$$<br><strong>这个问题没有解析解，只能通过迭代求解，EM就是可以用于求解这个问题的一种迭代算法</strong><br>例题的迭代过程见《统计学习方法》P156<br>NOTE:EM算法与初值的选择有关，选择不同的初值可能取得不同的参数估计值。</p><h5 id="具体算法"><a href="#具体算法" class="headerlink" title="具体算法"></a>具体算法</h5><p>「概念」完全数据vs不完全数据：$Y,Z$连在一起成为完全数据，$Y$成为不完全数据。</p><p><strong>具体EM算法如下：</strong><br>输入：观测变量$Y$，隐变量数据$Z$，联合分布$P(Y,Z|\theta)$，条件概率分布P(Z|Y,\theta)<br>输出：模型参数$\theta$</p><ol><li>选择初始值$\theta^{(0)}$，开始迭代</li><li>E步：记$\theta^{(i)}$为第$i$次迭代参数$\theta$的估计值，在第$i+1$次迭代的E步，计算<br>$$\begin {align}<br>Q(\theta,\theta^{(i)})&amp;= E_Z[logP(Y,Z|\theta)|Y,\theta^{(i)}]\\<br>&amp;=\sum\limits_{Z}logP(Y,Z|\theta)P(Z|Y,\theta^{(i)})<br>\end{align}$$<br>这里，$P(Z|Y,\theta^{(i)})$是在给定观测数据$Y$和当前的参数估计$\theta^{(i)}$下隐变量数据Z的条件概率分布。</li><li>M步：求使得$Q(\theta,\theta^{(i)})$极大化的$\theta$，确定第$i+1$次迭代的参数估计值$\theta^{(i+1)}$<br>$$\theta^{(i+1)}=arg\max_{\theta}Q(\theta,\theta^{(i)})$$</li><li>重复第2.3步，直至收敛。<br>其中$Q(\theta,\theta^{(i)})$是算法法核心，称为Q函数<br>Q函数是指完全数据的对数似然函数$logP(Y,Z|\theta)$关于在给定观测数据$Y$和当前参数$\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\theta^{(i)})$的期望称为Q函数。</li></ol><p><strong>NOTE:</strong><br>EM算法说明</p><ul><li>参数的初始值可以任意选择，但注意EM算法对初始值敏感</li><li>E步：$Q(\theta,\theta^{(i)})$中，第一个变元表示要极大化的参数，第二个变元是表示参数的当前估计值，每次迭代实际上在求Q函数的极大值</li><li>M步：求$Q(\theta,\theta^{(i)})$极大化，完成$\theta^{(i)} \rightarrow \theta^{(i+1)}$，每次迭代使似然函数增大或达到局部极值,但EM算法不能保证找到全军最优值</li><li>迭代停止：满足$||\theta^{(i+1)}-\theta^{(i)} ||&lt;\xi$</li><li>EM算法应用于生成模型的非监督学习。</li></ul><p><strong>EM算法的推导以及收敛性验证详见《统计学习方法P158》</strong><br>收敛性结果：<br>EM算法的收敛性包含关于对数似然函数序列$L(\theta^{(i)})$的收敛性和关于参数估计序列$\theta^{(i)}$的收敛性，此外，定理只能保证参数估计序列收敛到对数似然函数序列的稳定点，不能保证收敛到极大值点。应用中，初值选取非常重要，通常选择几个不同的初始值进行迭代，然后对比选择最优的结果。</p><h4 id="EM在高斯混合模型中的应用"><a href="#EM在高斯混合模型中的应用" class="headerlink" title="EM在高斯混合模型中的应用"></a>EM在高斯混合模型中的应用</h4><p>EM算法的重要应用是高斯混合模型的参数估计，在许多情况下，EM是学习高斯混合模型的有效方法。</p><h5 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h5><p>「高斯混合模型」具有如下概率分布模型：<br>$$P(y|\theta)=\sum\limits_{k=1}^{K}\alpha_k\phi(y|\theta_{k})$$<br>其中，$\alpha_k$是系数，$\alpha_k\geq0,\sum\limits_{k=1}^{K}\alpha_k=1;\phi(y|\theta_{k})$是高斯分布密度，$\theta_{k}=(\mu_k,\sigma_k^2)$<br>$$\phi(y|\theta_{k})=\frac{1}{\sqrt{2\pi}\sigma_k}exp\left(-\frac{(y-\mu_k)^2}{2\sigma_k^2}\right)$$<br>称第k个分模型</p><h5 id="高斯混合模型的EM算法"><a href="#高斯混合模型的EM算法" class="headerlink" title="高斯混合模型的EM算法"></a>高斯混合模型的EM算法</h5><p>假设观测数据$y_1,y_2,…,y_N$由高斯混合模型生成，<br>$$P(y|\theta)=\sum\limits_{k=1}^{K}\alpha_k\phi(y|\theta_{k})$$<br>其中，$\theta=(\alpha_1,\alpha_2,…,\alpha_K;\theta_1,\theta_2,…,\theta_K)$,用EM算法估计高斯混合模型的参数$\theta$<br>设想观测数据$y_j,j=1,2,…,N$是这样产生的：首先是依概率$a_k$选择第$k$个高斯分布分模型$\phi(y|\theta_{k})$；然后依第$k$个分模型的概率分布$\phi(y|\theta_{k})$生成观测数据$y_j$，观测数据$y_j$是已知的，反映观测数据$y_j$来自第$k$个分模型的数据是未知的，$k=1,2,…,K$，用隐变量$y_{jk}$，它是一个0-1随机变量。</p><p>高斯混合模型参数估计的EM算法(具体计算过程见《统计学习方法》P163)：<br>输入：观测数据$y1,y2,…,y_N$，高斯混合模型<br>输出：高斯混合模型参数</p><ol><li>取参数的初始值开始迭代</li><li>E步：依据当前模型参数，计算分模型$k$对观测数据$y_j$的响应度<br>$$\hat{y}_{jk}=\frac{\alpha_k\phi(y|\theta_{k})}{\sum\limits_{k=1}^{K}\alpha_k\phi(y|\theta_{k})}$$</li><li>M步：计算新一轮迭代的模型参数<br>$$\hat{\mu}_k=\frac{\sum\limits_{j=1}^{N}\hat{y}_{jk}y_j}{\sum\limits_{j=1}^{N}\hat{y}_{jk}},k=1,2,…,K$$<br>$$\hat{\sigma}_k^2=\frac{\sum\limits_{j=1}^{N}\hat{y}_{jk}(y_j-\mu_k)^2}{\sum\limits_{j=1}^{N}\hat{y}_{jk}},k=1,2,…,K$$<br>$$\hat{\alpha}_k=\frac{\sum\limits_{j=1}^{N}\hat{y}_{jk}}{N},k=1,2,…,K$$</li><li>重复2.3步直至收敛</li></ol><h4 id="广义期望极大算法（GEM）"><a href="#广义期望极大算法（GEM）" class="headerlink" title="广义期望极大算法（GEM）"></a>广义期望极大算法（GEM）</h4><p>EM算法还可以解释为F函数的极大-极大算法，基于这个解释有若干变形与推广，eg广义期望极大算法（Generalized Expectation Maximization）<br>更多内容详见《统计学习方法》P166</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h4&gt;&lt;p&gt;EM算法是一种迭代算法，它的每次迭代由两步组成：E步，求期望；M步，求极大，所以称为期望极大算法(Expectation Maximizat
      
    
    </summary>
    
      <category term="统计学习方法" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="EM" scheme="http://yoursite.com/tags/EM/"/>
    
      <category term="高斯混合模型" scheme="http://yoursite.com/tags/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="GEM" scheme="http://yoursite.com/tags/GEM/"/>
    
  </entry>
  
  <entry>
    <title>提升方法-1：Adaboost</title>
    <link href="http://yoursite.com/2019/03/20/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-1%EF%BC%9AAdaboost/"/>
    <id>http://yoursite.com/2019/03/20/提升方法-1：Adaboost/</id>
    <published>2019-03-20T03:35:00.000Z</published>
    <updated>2019-03-25T10:20:39.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>集成学习是将已有的弱的分类器或者回归模型通过一定的方法组合起来形成强的分类器或者回归模型的一种学习方法，它的思想就是“三个臭皮匠顶个诸葛亮”，综合得到的结论比单独的判断好，以袋套法(bagging)和提升法(boosting)为代表。</p><p><strong>袋套法(bagging) vs 提升法(boosting)：</strong><br>Boosting，各分类器之间有依赖关系，必须串行，比如Adaboost、GBDT、Xgboost<br>Bagging，各分类器之间没有依赖关系，可各自并行，比如随机森林（RF）</p><h4 id="Adaboost算法"><a href="#Adaboost算法" class="headerlink" title="Adaboost算法"></a>Adaboost算法</h4><ul><li><strong>问题1：每一轮是如何改变样本的权重？</strong><br>提升哪些在前一轮弱分类器错误分类的样本权重，降低那些被正确分类样本的权重，使得误分类的样本得到更大的关注。于是分类问题被一系列弱分类器“分而治之”。</li><li><strong>问题2. 如何将弱分类器组合成强分类器？</strong><br>加权多数表决法，加大分类误差率小的弱分类器的权重，减少分类误差率大的弱分类器的权重，使得分类误差率小的弱分类器在表决中起更大的作用。</li></ul><p><strong>算法</strong><br>输入：训练集$T=\lbrace(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\rbrace,y_i=\lbrace -1,+1 \rbrace$;弱学习算法<br>输出：最终分类器$G(x)$</p><ol><li>初始化训练样本的权值分布，<br>$$D_1=(w_{1,1},…,w_{1,i},…,w_{l,N}),w_{1,i}=\frac{1}{N}$$</li><li>反复学习基本分类器，对$m=1,2,…,M$<br>(a)使用具有权值分布$D_m$的训练集学习，得到基本分类器<br>$$G_m(x):X \rightarrow \lbrace -1,+1 \rbrace$$<br>(b)计算$G_m(x)$在训练集上的分类误差率<br>$$e_m=P(G_m(x_i)\neq y_i)=\sum\limits_{i=1}^{N}w_{m,i}I(G_m(x_i)\neq y_i)$$<br>(c)计算$G_m(x)$的系数<br>$$\alpha_m=\frac{1}{2}log\frac{1-e_m}{e_m}$$<br>当$e_m\leq\frac{1}{2},\alpha_m\geq0$，并且$\alpha$随着$e_m$的减少而增大，所以分类误差率越小的基本分类器在最终的分类器中作用越大。<br>(d)更新训练集的权值分布<br>$$D_{m+1}=(w_{m+1,1},…,w_{m+1,i},…,w_{m+l,N})$$<br>$$w_{m+1,i}=\frac{w_{m,i}}{Z_m}exp(-\alpha_my_iG_m(x_i)),i=1,2,…,N$$<br>$$Z_m=\sum\limits_{i=1}^{N}w_{m,i}exp(-\alpha_my_iG_m(x_i))$$<br>$Z_m$是规范化因子，使得$D_{m+1}$成为一个概率分布。</li><li>构建最终的分类器<br>$$G(x)=sign(\sum\limits_{m=1}^{M}\alpha_mG_m(x))$$</li></ol><h4 id="adaboost算法的训练误差分析"><a href="#adaboost算法的训练误差分析" class="headerlink" title="adaboost算法的训练误差分析"></a>adaboost算法的训练误差分析</h4><p>adaboost在学习过程中不断减少训练误差，即训练数据上的分类误差。<br>有如下定理：<br>adaboost算法的最终分类器的训练误差界为：<br>$$\frac{1}{N}\sum\limits_{i=1}^{N}I(G(x_i)\neq y_i) \leq \frac{1}{N}\sum_{i}exp(-y_if(x_i))=\prod_mZ_m$$ (更加详细的推导见统计学习方法p142)</p><h4 id="Adaboost算法解释"><a href="#Adaboost算法解释" class="headerlink" title="Adaboost算法解释"></a>Adaboost算法解释</h4><p>adaboost另外一种解释，即认为<strong>adaboost算法是加法模型，损失函数为指数函数，学习算法为前向分步算法</strong></p><ol><li>加法模型<br>$$f(x)=\sum\limits_{m=1}^{M}\beta_mb(x;\gamma_m)$$<br>$b(x;\gamma_m)$是基函数，$\gamma_m$基函数的参数，$\beta_m$是基函数的系数。</li><li>损失函数<br>$$\min_{\beta_m,\gamma_m} \quad\sum\limits_{i=1}^{N}L(y_i,\sum\limits_{m=1}^{M}\beta_mb(x_i;\gamma_m))$$<br>由于上述是一个复杂的优化问题，使用前向分布算法来求解这类问题。<br><strong>前向分布算法思想</strong>：由于学习的模型是加法模型，如果能够从前往后，每一步只学习一个基函数及其系数，逐步逼近优化函数目标式，那么就可以简化优化的复杂度，具体地，每步优化如下损失函数：<br>$$\min_{\beta,\gamma} \quad \sum\limits_{i=1}^{N}L(y_i,\beta b(x_i;\gamma))$$</li></ol><p><strong>前向分布算法：</strong><br>输入：训练集$T$，损失函数为$L(y,f(x))$，基函数集$\lbrace b(x;\gamma)\rbrace$<br>输出：加法模型$f(x)$</p><ul><li>初始化$f_0(x)=0$</li><li>对$m=1,2,…,M$<br>(a)极小化损失函数<br>$$(\beta_m,\gamma_m)=arg\min_{\beta,\gamma}\quad\sum\limits_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))$$<br>(b)更新<br>$$f_m(x)=f_{m-1}(x)+\beta_mb(x;\gamma_m)$$</li><li>得到加法模型<br>$$f(x)=f_M(x)=\sum\limits_{m=1}^{M}\beta_mb(x;\gamma_m)$$<br>这样，前向分步算法将同时求解从$m=1$到$M$所有参数$\beta_m,\gamma_m$的优化问题简化为逐次求解各个$\beta_m,\gamma_m$的优化问题。</li></ul><h5 id="前向分步算法与Adaboost"><a href="#前向分步算法与Adaboost" class="headerlink" title="前向分步算法与Adaboost"></a>前向分步算法与Adaboost</h5><p>最终分类器模型为：<br>$$f(x)=\sum\limits_{m=1}^{M}\alpha_mG_m(x)$$<br>损失函数为：【指数损失函数】<br>$$L(y,f(x))=exp(-yf(x))$$<br>在第$m$轮迭代得到$\alpha_m,G_m(x),f_m(x)$<br>$$f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)$$<br>目标是使前向分步算法得到的$\alpha_m,G_m(x)$使$f_m(x)$在训练集$T$上的指数损失最小，即<br>$$(\alpha_m,G_m(x))=arg \min_{\alpha,G}\sum\limits_{i=1}^{N}exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]$$<br>上式可以表示为：<br>$$(\alpha_m,G_m(x))=arg \min_{\alpha,G}\sum\limits_{i=1}^{N}\hat{w}_{m,i}exp[-y_i\alpha G(x_i)]$$<br>其中，$\hat{w}_{m,i}=exp[-y_if_{m-1}(x_i)]$，其中$\hat{w}_{m,i}$既不依赖$\alpha$也不依赖$G$,所以与最小化无关，但$\hat{w}_{m,i}$依赖于$f_{m-1}(x)$，随每次迭代发生变化<br>使得上式达到最小的$\alpha_m^{\ast}$和$G_m^{\ast}(x)$，就是adaboost算法所得到的$\alpha_m,G_m(x)$</p><h4 id="提升树🌲"><a href="#提升树🌲" class="headerlink" title="提升树🌲"></a>提升树🌲</h4><p>提升方法：采用加法模型(基函数的线性组合)与前向分步算法。<br>提升树：以决策树为基函数的提升方法。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树，即是CART作为基函数。<br>提升树的模型可以表示为决策树的加法模型：$$f_M(x)=\sum\limits_{m=1}^{M}T(x;\theta_m)$$<br>其中$T(x;\theta_m)$为决策树，$\theta_m$为决策树参数，$M$为树的个数<br><strong>提升树算法</strong><br>初始提升树为$f_0(x)=0$<br>第$m$步的模型是：$f_m(x)=f_{m-1}(x)+T(x;\theta_m)$<br>当$f_{m-1}(x)$为当前模型，通过经验风险极小化确定下一颗决策树的参数$\theta_m$<br>$$\hat{\theta}_{m}=arg \min_{\theta_m}\sum\limits_{i=1}^{N}L(y_i,f_{m-1}(x_i)+T(x;\theta_m))$$<br><strong>针对不同问题的提升树学习方法主要区别在于损失函数的不同</strong>🤓<br>回归问题用平方误差损失函数；分类问题用指数损失函数。</p><p>下面以回归问题的提升树为例：<br>采用平方误差损失函数：<br>$$L(y,f_{m-1}(x)+T(x;\theta_m))=[y-f_{m-1}(x)-T(x;\theta_m)]^2$$其中$r=y-f_{m-1}(x)$是当前数据模型拟合数据的残差，所以对于回归问题的提升树算法来说，只需要简单地拟合当前模型的残差。</p><p><strong>具体算法如下:</strong><br>输入：训练集$T=\lbrace(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\rbrace,y_i=\lbrace -1,+1 \rbrace$;<br>输出：提升树$f_M(x)$</p><ol><li>初始化$f_0(x)=0$</li><li>对$m=1,2,…,M$<br>计算残差：$r_{m,i}=y_i-f_{m-1}(x_i),i=1,2,…,N$<br>拟合残差：$r_{m,i}$学习一个回归树，得到$T(x;\theta_m)$<br>更新：$f_m(x)=f_{m-1}(x)+T(x;\theta_m)$</li><li>得到回归问题的提升树<br>$$f_M(x)=\sum\limits_{m=1}^{M}T(x;\theta_m)$$</li></ol><h5 id="梯度提升"><a href="#梯度提升" class="headerlink" title="梯度提升"></a>梯度提升</h5><p>提升树利用加法模型和前向分布算法实现学习的优化过程，当损失函数为平方损失和指数损失函数时，优化比较简单，但对于一般损失函数而言，每一步优化并不容易。<br>对于这个问题，利用<strong>梯度提升算法</strong>【利用最速下降法的近似，其关键是利用损失函数的负方向在当前模型的值】,表示如下：<br>$$\left(\frac{dL(y,f(x_i))}{df(x_i)}\right)_{f(x)=f_{m-1}(x)}$$<br>这个值作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p><p><strong>梯度提升算法：</strong><br>输入：训练集<br>输出：回归树$\hat{f}(x)$</p><ol><li>初始化$f_0(x)=arg \min\limits_{c}\sum\limits_{i=1}^{N}L(y_i,c)$</li><li>对$m=1,2,…,M$<br>(a)计算残差：$r_{m,i}=\left(\frac{dL(y,f(x_i))}{df(x_i)}\right)_{f(x)=f_{m-1}(x)}$<br>(b)对$r_{m,i}$拟合一个回归树，得到第$m$课树的叶子结点区域$R_{mj},j=1,2,…,J$<br>(c)对$j=1,2,…,J$计算$c_{m,j}=arg \min\limits_{c}\sum\limits_{x_i\in R_{mj}}L(y_i,f_{m-1}(x_i)+c)$<br>(d)更新$f_m(x)=f_{m-1}(x)+\sum\limits_{j=1}^{J}c_{mj}I(x\in R_{mj})$</li><li>得到回归树<br>$$\hat{f}(x)=f_M(x)=\sum\limits_{m=1}^{M}\sum\limits_{j=1}^{J}c_{mj}I(x\in R_{mj})$$<br>解释如下：<br>1：估计是损失函数极小化的常数值，它是只有一个根结点的树。<br>2(a)：计算当前模型在损失函数的负梯度的值，将它作为残差的估计，对平方损失函数它就是残差，对一般损失函数，它是残差的近似<br>2(b)：估计回归树叶子结点区域，以拟合残差的近似值<br>2(c)：利用线性搜索估计叶子结点区域的值，使得损失函数极小化<br>2(d)：更新回归树<br>3：输出最终的模型</li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>除了上述分析到的adaboost、提升树、梯度提升树外，下一博文将介绍工业上常用的两个模型GBDT和xgboost。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;集成学习是将已有的弱的分类器或者回归模型通过一定的方法组合起来形成强的分类器或者回归模型的一种学习方法，它的思想就是“三个臭皮匠顶个诸葛亮”
      
    
    </summary>
    
      <category term="统计学习方法" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="boosting" scheme="http://yoursite.com/tags/boosting/"/>
    
      <category term="adaboost" scheme="http://yoursite.com/tags/adaboost/"/>
    
      <category term="提升树" scheme="http://yoursite.com/tags/%E6%8F%90%E5%8D%87%E6%A0%91/"/>
    
      <category term="梯度提升" scheme="http://yoursite.com/tags/%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>支持向量机(SVM)-2:非线性支持向量机</title>
    <link href="http://yoursite.com/2019/03/19/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-2-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <id>http://yoursite.com/2019/03/19/支持向量机-SVM-2-非线性支持向量机/</id>
    <published>2019-03-19T04:18:00.000Z</published>
    <updated>2019-03-19T10:03:05.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="非线性svm与核函数"><a href="#非线性svm与核函数" class="headerlink" title="非线性svm与核函数"></a>非线性svm与核函数</h4><p>当分类问题是非线性，可以使用非线性svm，主要的特点是利用核函数。</p><h5 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h5><p>非线性分类问题😵<br>对于训练数据集，能用一个超曲面将正负例正确分开，则称该问题为<strong>非线性可分问题</strong><br>非线性问题往往不好求解，所以进行非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题求解原来的非线性问题。💃💃</p><p>线性分类法求解非线性分类问题：使用变换，将原空间数据映射到新空间；然后在新空间利用线性分类学习方法从训练集中学习分类模型。<strong>核技巧就属于这样的方法</strong></p><p>核技巧应用到svm的基本思想：通过非线性变换将输入空间$X$(欧氏空间&amp;离散集合)对应于特征空间$H$(希尔伯特空间)，使得输入空间的超曲面模型对应特征空间的超平面模型，最后分类问题的学习任务是通过在<strong>特征空间</strong>在求解线性支持向量机就可以完成。<br>如果存在一个从$X$到$H$的映射，映射关系表示如下：$$\phi(x):X\rightarrow H$$<br>使得对所有的$x,z\in X$，函数$K(x,z)$满足条件$$K(x,z)=\phi(x)\cdot\phi(z)$$<br>则称$K(x,z)$为核函数，$\phi(x)$为映射函数，$\phi(x)\cdot\phi(z)$为$\phi(x)和\phi(z)$内积</p><p><strong>核技巧思想</strong><br>在学习与预测中只定义核函数$K(x,z)$，而不显式地定义映射函数$\phi(x)$，通常计算核函数比计算内积更容易。对于给定的核函数$K(x,z)$，$\phi(x)$的取法不唯一，可以取不同的特征空间，即使是同一特征空间也可以取不同的映射。</p><p>在svm中的应用：线性svm的对偶问题中，无论是目标函数还是决策函数都涉及到实例之间的内积，在对偶问题的目标函数$x_i\cdot x_j$，可以使用核函数$K(x_i,x_j)=\phi(x_i)\cdot\phi(x_j)$来代替。<br>所以对偶问题的目标函数表示为：<br>$$W(\alpha)=\frac{1}{2}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N}a_ia_jy_iy_jK(x_i,x_j)-\sum\limits_{i=1}^{N}\alpha_i$$<br>分类决策函数表示为：<br>$$f(x)=sign(\sum\limits_{i=1}^{N_s}\alpha_i^{\ast}y_iK(x_i,x)+b^{\ast})$$<br>即，在核函数给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的svm。学习过程是隐式地在特征空间进行的，不需要定义特征空间和映射函数，这样的技巧称为核技巧。</p><h5 id="正定核"><a href="#正定核" class="headerlink" title="正定核"></a>正定核</h5><p><strong>核函数$K(x,z)$需为正定核函数</strong></p><p>正定核的充要条件：设$K:X\times X\rightarrow R$是对称函数，则$K(x,z)$为正定核函数的充要条件是对任意$x_i\in X,i=1,2,…,m,K(x,m)$对应的Gram矩阵：$$K=[K(x_i,x_j)]_{m\times m}$$<br>是半正定的</p><h5 id="常用的核函数"><a href="#常用的核函数" class="headerlink" title="常用的核函数"></a>常用的核函数</h5><ol><li>线性核函数<br>$$K(x,z)=(x\cdot z)$$<br>适用于线性svm，其实就是在原始的输出空间进行学习</li><li>多项式核函数<br>$$K(x,z)=(x\cdot z+1)^p$$<br>对应的svm是一个$p$次多项式分类器，分类决策函数为：<br>$$f(x)=sign\left(\sum\limits_{i=1}^{N_s}\alpha_i^{\ast}y_i(x_i\cdot x+1)^p+b^{\ast}\right)$$</li><li>高斯核函数<br>$$K(x,z)=exp\left(-\frac{||x-z||^2}{2\sigma}\right)$$<br>对应的svm是高斯径向基函数分类器，分类决策函数表示为:<br>$$f(x)=sign\left(\sum\limits_{i=1}^{N_s}\alpha_i^{\ast}y_iexp(-\frac{||x-z||^2}{2\sigma})+b^{\ast}\right)$$</li><li>字符串核函数<br>核函数不仅可以定义在欧氏距离还可以定义在离散数据的集合上，eg字符串核函数是定义在字符串集合上的核函数，字符串核函数在文本分类、信息检索等方法有应用。</li><li>sigmod核函数<br>采用sigmoid核函数，支持向量机实现的就是一种多层神经网络<br>更多核函数参考博文 <a href="https://blog.csdn.net/wsj998689aa/article/details/47027365" target="_blank" rel="noopener">总结一下
